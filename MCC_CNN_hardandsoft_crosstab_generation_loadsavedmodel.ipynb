{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21abbe08-58e5-4a3d-a571-0f41944c434e",
   "metadata": {},
   "source": [
    "# Use the model checkpoint to get the latest model and the misclassified instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afc7e723-a0af-42f3-a848-de06aafd386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cdbfe30-eadb-4cce-8adf-4e4d02740ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size=1024\n",
    "\n",
    "\n",
    "# epoch 4, accuracy 0.3099\n",
    "# epoch 7, accuracy 0.4104\n",
    "# epoch 12, accuracy 0.5020\n",
    "# epoch 68, accuracy 0.7192\n",
    "# epoch 26, accuracy 0.6027\n",
    "# epoch 95, accuracy 0.7410\n",
    "\n",
    "\n",
    "\n",
    "# 10k 10k\n",
    "# epoch 62, accuracy 0.8551\n",
    "#threshold,sample_size,epoch_to_load = 10000,10000,62\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33f500ba-34e5-4590-9426-b438838ffbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/genomeACTGbases_sample_3000_3000_2020-07---2021-05.csv\n",
      "models/MCC_CNNv5_3000_3000_LOO_England_64/MCC_CNNv5_3000_3000_LOO_England_epoch41.pth\n",
      "CNNv5_3000_3000_LOO_England\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "start_month='2020-07'\n",
    "end_month='2021-05'\n",
    "data_path=f'data/genomeACTGbases_sample_{threshold}_{sample_size}_{start_month}---{end_month}.csv'\n",
    "print(data_path)\n",
    "data=pd.read_csv(data_path)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GenomeDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, base_to_index, label_to_index=None):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.base_to_index = base_to_index\n",
    "        self.label_to_index = label_to_index or self._generate_label_to_index()\n",
    "\n",
    "    def _generate_label_to_index(self):\n",
    "        unique_labels = sorted(set(self.labels))  # Sort labels to ensure consistency\n",
    "        return {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoded_sequence = self.one_hot_encode(sequence)\n",
    "        # Convert labels to integers if necessary\n",
    "        label_index = self.label_to_index[label] if isinstance(label, str) else label\n",
    "        return encoded_sequence, torch.tensor(label_index, dtype=torch.long)\n",
    "\n",
    "    def one_hot_encode(self, sequence):\n",
    "        encoded = torch.zeros((len(sequence), len(self.base_to_index)), dtype=torch.float32)\n",
    "        for i, base in enumerate(sequence):\n",
    "            if base in self.base_to_index:\n",
    "                encoded[i, self.base_to_index[base]] = 1\n",
    "        return encoded\n",
    "\n",
    "\n",
    "model_name=f'CNNv5_{threshold}_{sample_size}'\n",
    "checkpoint_path = f'models/MCC_{model_name}_{n_filter}/MCC_{model_name}_epoch{epoch_to_load}.pth'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "print('checkpoint_path',checkpoint_path)\n",
    "print('model_name',model_name)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "target = 'region'\n",
    "bases = {'*', '-', 'A', 'C', 'G', 'T'}\n",
    "base_to_index = {base: i for i, base in enumerate(sorted(bases))}\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data['sequence'], data[target], test_size=0.4, random_state=42)\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "test_dataset = GenomeDataset(X_test.tolist(), y_test.tolist(), base_to_index)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b5b765e-af0b-40cf-98c9-9a14f66b6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "class CNNModelV5(nn.Module):\n",
    "    def __init__(self, input_channels, n_filter, n_class):\n",
    "        super(CNNModelV5, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, n_filter, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm1d(n_filter)\n",
    "        self.conv2 = nn.Conv1d(n_filter, n_filter, kernel_size=4)\n",
    "        self.bn2 = nn.BatchNorm1d(n_filter)\n",
    "        self.conv3 = nn.Conv1d(n_filter, n_filter, kernel_size=5)\n",
    "        self.bn3 = nn.BatchNorm1d(n_filter)\n",
    "        self.conv4 = nn.Conv1d(n_filter, n_filter, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(n_filter)\n",
    "        self.conv5 = nn.Conv1d(n_filter, n_filter, kernel_size=3)\n",
    "        self.bn5 = nn.BatchNorm1d(n_filter)    \n",
    "        self.conv6 = nn.Conv1d(n_filter, n_filter, kernel_size=3)\n",
    "        self.bn6 = nn.BatchNorm1d(n_filter) \n",
    "        self.maxpool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(n_filter, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))  \n",
    "        x = F.relu(self.bn5(self.conv5(x))) \n",
    "        x = F.relu(self.bn6(self.conv6(x))) \n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x    \n",
    "      \n",
    "  \n",
    "      \n",
    "\n",
    "n_class=len(list(set(list(data['region']))))\n",
    "input_channels = 6\n",
    "n_filter = 64\n",
    "cnn_model = CNNModelV5(input_channels, n_filter=n_filter, n_class=n_class)\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, cnn_model):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.cnn_model(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe060c-4b47-41ca-8cec-b063998c818d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10533ece-8828-409f-9508-eb6755f4d362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (cnn_model): CNNModelV5(\n",
       "    (conv1): Conv1d(6, 64, kernel_size=(3,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(4,), stride=(1,))\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
       "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "    (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv5): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "    (bn5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv6): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "    (bn6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "    (fc): Linear(in_features=64, out_features=19, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNModel(cnn_model) \n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09308ca7-50fa-47ea-9c70-22d0d990f31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncriterion = torch.nn.CrossEntropyLoss()\\n\\ntest_loss = 0.0\\ncorrect_predictions = 0\\ntotal_samples = 0\\n\\nwith torch.no_grad():\\n    for inputs, labels in test_loader:\\n        # No need to move inputs and labels to device (GPU or CPU)\\n        outputs = model(inputs)\\n        loss = criterion(outputs, labels)\\n        test_loss += loss.item()\\n        _, predicted = torch.max(outputs, 1)\\n        correct_predictions += (predicted == labels).sum().item()\\n        total_samples += labels.size(0)\\n\\navg_test_loss = test_loss / len(test_loader)\\ntest_accuracy = correct_predictions / total_samples\\n\\nprint(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # No need to move inputs and labels to device (GPU or CPU)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f83d2c2c-5fd7-4969-abba-3d9d60417673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Australia',\n",
       " 1: 'Belgium',\n",
       " 2: 'Canada',\n",
       " 3: 'Denmark',\n",
       " 4: 'France',\n",
       " 5: 'Germany',\n",
       " 6: 'Iceland',\n",
       " 7: 'India',\n",
       " 8: 'Italy',\n",
       " 9: 'Japan',\n",
       " 10: 'Luxembourg',\n",
       " 11: 'Netherlands',\n",
       " 12: 'Portugal',\n",
       " 13: 'Scotland',\n",
       " 14: 'SouthAfrica',\n",
       " 15: 'Spain',\n",
       " 16: 'Switzerland',\n",
       " 17: 'USA',\n",
       " 18: 'Wales'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_label = {v: k for k, v in test_dataset.label_to_index.items()}\n",
    "index_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96e42f-f49e-477c-a75f-0c4c37484e37",
   "metadata": {},
   "source": [
    "# hard and soft classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3afee39-058b-40d9-a3c7-fb0ff8c56365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set prediction accuracy: 0.7278\n"
     ]
    }
   ],
   "source": [
    "incorrectly_classified = []\n",
    "\n",
    "total_samples = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "# Soft classification\n",
    "confusion_matrix = torch.zeros(n_class, n_class)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(probabilities, 1)\n",
    "        \n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        \n",
    "        incorrect_indices = (predicted != labels).nonzero(as_tuple=False).squeeze()\n",
    "        for idx in incorrect_indices:\n",
    "            incorrectly_classified.append((index_to_label[predicted[idx].item()], index_to_label[labels[idx].item()]))\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            confusion_matrix[predicted[i], labels[i]] += 1\n",
    "\n",
    "prediction_accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f'Test set prediction accuracy: {prediction_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47439938-50aa-4328-8902-c3677bf91ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Initialize lists to store incorrectly classified data points\\nincorrectly_classified = []\\n\\n# Initialize variables to track correct predictions\\ntotal_samples = 0\\ncorrect_predictions = 0\\n\\n# Soft classification\\nconfusion_matrix = torch.zeros(n_class, n_class)\\n\\n\\n# Evaluate the model and gather results\\nwith torch.no_grad():\\n    for inputs, labels in test_loader:\\n        outputs = model(inputs)\\n        _, predicted = torch.max(outputs, 1)\\n        \\n        # Hard classification\\n        # Convert numerical labels to country names\\n        predicted_countries = [index_to_label[idx.item()] for idx in predicted]\\n        true_countries = [index_to_label[idx.item()] for idx in labels]\\n        # Update correct predictions count\\n        total_samples += len(labels)\\n        correct_predictions += (predicted == labels).sum().item()\\n        # Gather incorrectly classified data points\\n        for pred_country, true_country in zip(predicted_countries, true_countries):\\n            if pred_country != true_country:\\n                incorrectly_classified.append([pred_country, true_country])\\n        \\n        # Soft classification\\n        probabilities = torch.softmax(outputs, dim=1)  # Get softmax probabilities\\n        \\n        # Iterate over the batch\\n        for idx, true_label in enumerate(labels):\\n            true_label = true_label.item()\\n            for predicted_label, softmax_score in enumerate(probabilities[idx]):\\n                # Add the softmax score to the corresponding matrix cell\\n                confusion_matrix[predicted_label][true_label] += softmax_score\\n  \\n# Calculate prediction accuracy\\nprediction_accuracy = correct_predictions / total_samples\\n\\nprint(f'Test set prediction accuracy: {prediction_accuracy:.4f}')\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "incorrectly_classified = []\n",
    "\n",
    "total_samples = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "# Soft classification\n",
    "confusion_matrix = torch.zeros(n_class, n_class)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Hard classification\n",
    "        # Convert numerical labels to country names\n",
    "        predicted_countries = [index_to_label[idx.item()] for idx in predicted]\n",
    "        true_countries = [index_to_label[idx.item()] for idx in labels]\n",
    "\n",
    "        total_samples += len(labels)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        for pred_country, true_country in zip(predicted_countries, true_countries):\n",
    "            if pred_country != true_country:\n",
    "                incorrectly_classified.append([pred_country, true_country])\n",
    "        \n",
    "        # Soft classification\n",
    "        probabilities = torch.softmax(outputs, dim=1)  # Get softmax probabilities\n",
    "        \n",
    "        for idx, true_label in enumerate(labels):\n",
    "            true_label = true_label.item()\n",
    "            for predicted_label, softmax_score in enumerate(probabilities[idx]):\n",
    "                # Add the softmax score to the corresponding matrix cell\n",
    "                confusion_matrix[predicted_label][true_label] += softmax_score\n",
    "  \n",
    "prediction_accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f'Test set prediction accuracy: {prediction_accuracy:.4f}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a8f2bfe-28f8-426a-887a-e0921d73dd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification Crosstab:\n",
      "Predicted    Australia  Belgium  Canada  Denmark  France  Germany  Iceland  \\\n",
      "Actual                                                                       \n",
      "Australia            0        1       0        0       1        0        0   \n",
      "Belgium              2        0      46       42      10       32       14   \n",
      "Canada               5       36       0       20      12       14        3   \n",
      "Denmark              0       39       2        0      44       10       22   \n",
      "France               3        6       5        3       0       17        2   \n",
      "Germany              8        7       4        0      14        0        6   \n",
      "Iceland              0        3       4        2       0        7        0   \n",
      "India                6        5      11        0      13       16        2   \n",
      "Italy                4       10       1        0      24       24        1   \n",
      "Japan                0        2       1        2       0        1        1   \n",
      "Luxembourg           0        0       0        0      19        5        0   \n",
      "Netherlands          0       28       0       66      10        3        5   \n",
      "Portugal            12        0       2        0      44       35        4   \n",
      "Scotland             2       31      16       35      37       29       19   \n",
      "SouthAfrica         12        4       3        0      14        4        1   \n",
      "Spain               22        0       2        0      12        5        0   \n",
      "Switzerland          2        1       5        1      20       20       61   \n",
      "USA                 30        3      33       10      35       48       10   \n",
      "Wales                4        3       0        0      10        8        0   \n",
      "\n",
      "Predicted    India  Italy  Japan  Luxembourg  Netherlands  Portugal  Scotland  \\\n",
      "Actual                                                                          \n",
      "Australia        1      0      1           1            0         2         1   \n",
      "Belgium         10      2      5          11           26         6        63   \n",
      "Canada          11      3      3           0            4         0        20   \n",
      "Denmark          0      0      0          16           65         1        26   \n",
      "France          11     16      0          16            1        20         4   \n",
      "Germany         15     13      3           7            0        12         6   \n",
      "Iceland          2      2      0           0            0         2         2   \n",
      "India            0     10     21           3            4         0         0   \n",
      "Italy           35      0      2           9            0         2         7   \n",
      "Japan            7      2      0           2            2         0         1   \n",
      "Luxembourg       3      7      9           0            9         4         0   \n",
      "Netherlands      2      0      3          11            0         1        18   \n",
      "Portugal         0      1      0           5            1         0         2   \n",
      "Scotland         3      7      0           2           47         4         0   \n",
      "SouthAfrica     19     14      4          15            5         1         0   \n",
      "Spain            4     10      5           3            0         5         1   \n",
      "Switzerland     19     10      2           3            1         7         1   \n",
      "USA             27      2      9          12            5        11        12   \n",
      "Wales            2      8      0           1            0         0        17   \n",
      "\n",
      "Predicted    SouthAfrica  Spain  Switzerland  USA  Wales  \n",
      "Actual                                                    \n",
      "Australia              0      2            0    2      0  \n",
      "Belgium                0      0            2   16     11  \n",
      "Canada                 0      1            4   45      2  \n",
      "Denmark                0      1            0    5      6  \n",
      "France                 3     11           18   18      8  \n",
      "Germany               13      1            7   16      1  \n",
      "Iceland                1      0           14    2      2  \n",
      "India                  4     11           15   17      5  \n",
      "Italy                 19     29           14   21     29  \n",
      "Japan                  2      3            1    4      0  \n",
      "Luxembourg             3      0            3   12      1  \n",
      "Netherlands            0      0            1    0      7  \n",
      "Portugal               3      5            4    5      0  \n",
      "Scotland               0      4            2   14     97  \n",
      "SouthAfrica            0      7           18   23      8  \n",
      "Spain                 25      0           36   12     20  \n",
      "Switzerland           17     37            0   13      2  \n",
      "USA                   15     21            7    0     25  \n",
      "Wales                  8      4            3    9      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "misclassified_df = pd.DataFrame(incorrectly_classified, columns=['Actual', 'Predicted'])\n",
    "\n",
    "misclassification_crosstab = pd.crosstab(index=misclassified_df['Actual'], columns=misclassified_df['Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "print(\"Misclassification Crosstab:\")\n",
    "print(misclassification_crosstab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0cafedc-96a9-4977-9e1c-f282ec5a271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crosstable/MCC_CNNv5_3000_3000_LOO_England_accuracy0.7278_2020-07---2021-05.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'crosstable/MCC_{model_name}_accuracy{prediction_accuracy:.4f}_{start_month}---{end_month}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75fbfdbd-5517-4475-bbaa-11e584d2b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassification_crosstab.to_pickle(f'crosstable/MCC_{model_name}_accuracy{prediction_accuracy:.4f}_{start_month}---{end_month}.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c5448-0fe0-40d8-bd31-8e4d5b2c3fca",
   "metadata": {},
   "source": [
    "# Soft misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "205dd020-b1d1-41ce-a672-e47ca6656709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class_labels = list(test_dataset.label_to_index.keys())\n",
    "soft_misclassified_df = pd.DataFrame(confusion_matrix.numpy(), index=class_labels, columns=class_labels)\n",
    "soft_misclassified_df.to_pickle(f'crosstable/MCC_softmax_{model_name}_accuracy{prediction_accuracy:.4f}_{start_month}---{end_month}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc2aef-9739-4e64-9ac2-c0fd79b3a587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44af7e3f-c7c8-4df8-a55f-9768b580183e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
